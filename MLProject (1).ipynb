{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "V8-yl-s-WKMG"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dggLVarNxxvC"
      },
      "source": [
        "## 0.1 Install package and download source code/image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGL97-GXjSUw"
      },
      "source": [
        "%%capture\n",
        "#@title\n",
        "!pip install tensorflow_addons\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "# Download source code.\n",
        "if \"efficientnetv2\" not in os.getcwd():\n",
        "  !git clone --depth 1 https://github.com/google/automl\n",
        "  os.chdir('automl/efficientnetv2')\n",
        "  sys.path.append('.')\n",
        "else:\n",
        "  !git pull\n",
        "\n",
        "def download(m):\n",
        "  if m not in os.listdir():\n",
        "    !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/v2/{m}.tgz\n",
        "    !tar zxf {m}.tgz\n",
        "  ckpt_path = os.path.join(os.getcwd(), m)\n",
        "  return ckpt_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlh_S6M9ahe5"
      },
      "source": [
        "MODEL = 'efficientnetv2-b0'\n",
        "import effnetv2_model\n",
        "\n",
        "# Download checkpoint.\n",
        "ckpt_path = download(MODEL)\n",
        "if tf.io.gfile.isdir(ckpt_path):\n",
        "  ckpt_path = tf.train.latest_checkpoint(ckpt_path)\n",
        "\n",
        "# Download label map file\n",
        "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/eval_data/labels_map.txt -O labels_map.txt\n",
        "labels_map = 'labels_map.txt'\n",
        "\n",
        "# Download images\n",
        "image_file = 'panda.jpg'\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O {image_file}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "tf.keras.backend.clear_session()\n",
        "model = effnetv2_model.EffNetV2Model(model_name=MODEL)\n",
        "_ = model(tf.ones([1, 224, 224, 3]), training=False)\n",
        "model.load_weights(ckpt_path)\n",
        "cfg = model.cfg"
      ],
      "metadata": {
        "id": "9ruCfdnYlVYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW90fiMiyg4n"
      },
      "source": [
        "# EfficientNetV2 on CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PC6QrMlylOF"
      },
      "source": [
        "!python main_tf2.py --mode=traineval  --model_name=efficientnetv2-b0  --dataset_cfg=cifar10Ft --model_dir={MODEL}_finetune --hparam_str=\"train.ft_init_ckpt={MODEL},runtime.strategy=gpus,train.batch_size=64\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "kWwyNI5yh4FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Efficienetv2 on Imagenette dataset\n"
      ],
      "metadata": {
        "id": "oFE07c19xfRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'batch_size': 64,\n",
        "    'epochs': 15\n",
        "}"
      ],
      "metadata": {
        "id": "EYqPCfm4yJIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_set, test_set), info = tfds.load(\"imagenette\", \n",
        "                                           split=[\"train\", \"validation\"],\n",
        "                                           as_supervised=True, with_info=True)\n",
        "\n",
        "class_names = info.features[\"label\"].names\n",
        "n_classes = info.features[\"label\"].num_classes\n",
        "\n",
        "def preprocess_img(img, label):\n",
        "    img = tf.image.resize(img, (224, 224))\n",
        "    img = img/255\n",
        "    return img, label\n",
        "\n",
        "train_set = train_set.map(preprocess_img).batch(config['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
        "test_set = test_set.map(preprocess_img).batch(config['batch_size'], drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "history = model.fit(train_set, epochs=15, validation_data=test_set)"
      ],
      "metadata": {
        "id": "5woB0VYAVhrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying Resnet model on  cifar10 dataset"
      ],
      "metadata": {
        "id": "Ni4uRsh4ylR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture\n",
        "base_model = ResNet50V2(include_top=False, input_shape=(32, 32, 3))\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Augment the training data with random transformations\n",
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(datagen.flow(train_images, train_labels, batch_size=64), epochs=50, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "VLie58Gahs4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pretrained resnet50 on  cifar10"
      ],
      "metadata": {
        "id": "2g4R3tKyyihP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mm = keras.applications.ResNet50V2(include_top=False, input_shape=input_shape, weights=\"imagenet\")\n",
        "out = mm.outputs[0]\n",
        "\n",
        "nn = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(out)\n",
        "nn = keras.layers.Activation(\"linear\", dtype=\"float32\")(nn)\n",
        "nn = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"predictions\", dtype=\"float32\")(nn)\n",
        "resnet50v2_imagenet = keras.models.Model(mm.inputs[0], nn)\n",
        "\n",
        "resnet50v2_imagenet.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['acc'])\n",
        "history_resnet50v2_imagenet = resnet50v2_imagenet.fit(train_dataset, epochs=15, validation_data=test_dataset)\n",
        "with open(\"history_resnet50v2_imagenet.json\", \"w\") as ff:\n",
        "    json.dump(history_resnet50v2_imagenet.history, ff)"
      ],
      "metadata": {
        "id": "doM-jk7PheH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EfficientNetV2 on Food101"
      ],
      "metadata": {
        "id": "e1df1QZB6Apd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the Food101 dataset from TFDS\n",
        "dataset = tfds.load('food101', split='train[:80%]', as_supervised=True)\n",
        "\n",
        "# Get the number of classes in the dataset\n",
        "num_classes = dataset.num_classes\n",
        "\n",
        "# Define the input shape of the images\n",
        "input_shape = (224, 224, 3)"
      ],
      "metadata": {
        "id": "BoEDCeJMRGMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = info.features[\"label\"].names\n",
        "n_classes = info.features[\"label\"].num_classes\n",
        "\n",
        "def preprocess_img(img, label):\n",
        "    img = tf.image.resize(img, (224, 224))\n",
        "    img = img/255\n",
        "    return img, label\n",
        "\n",
        "train_set = train_set.map(preprocess_img).batch(config['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
        "test_set = test_set.map(preprocess_img).batch(config['batch_size'], drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model.compile(\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.09),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "history = model.fit(train_set, epochs=15, validation_data=test_set)"
      ],
      "metadata": {
        "id": "DrtRbbuoRGOg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}